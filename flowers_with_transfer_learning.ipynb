{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "source": [
    "## Download the Flowers Dataset using TensorFlow Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1mDownloading and preparing dataset 218.21 MiB (download: 218.21 MiB, generated: 221.83 MiB, total: 440.05 MiB) to /home/ritesh/tensorflow_datasets/tf_flowers/3.0.1...\u001b[0m\n",
      "Dl Completed...: 100%|██████████| 5/5 [00:59<00:00, 11.81s/ file]\u001b[1mDataset tf_flowers downloaded and prepared to /home/ritesh/tensorflow_datasets/tf_flowers/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(training_set, validation_set), dataset_info = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:70%]', 'train[70%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "source": [
    "## Explore Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Number of Classes: 5\nTotal Number of Training Images: 2569\nTotal Number of Validation Images: 1101 \n\n"
     ]
    }
   ],
   "source": [
    "num_classes = dataset_info.features['label'].num_classes\n",
    "\n",
    "num_training_examples = 0\n",
    "num_validation_examples = 0\n",
    "\n",
    "for example in training_set:\n",
    "  num_training_examples += 1\n",
    "\n",
    "for example in validation_set:\n",
    "  num_validation_examples += 1\n",
    "print('Total Number of Classes: {}'.format(num_classes))\n",
    "print('Total Number of Training Images: {}'.format(num_training_examples))\n",
    "print('Total Number of Validation Images: {} \\n'.format(num_validation_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Image 1 shape: (333, 500, 3) label: 2\nImage 2 shape: (212, 320, 3) label: 3\nImage 3 shape: (240, 320, 3) label: 3\nImage 4 shape: (240, 320, 3) label: 4\nImage 5 shape: (317, 500, 3) label: 3\n"
     ]
    }
   ],
   "source": [
    "for i, example in enumerate(training_set.take(5)):\n",
    "  print('Image {} shape: {} label: {}'.format(i+1, example[0].shape, example[1]))"
   ]
  },
  {
   "source": [
    "## Reformate Images and create batches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_RES = 224\n",
    "\n",
    "def format_image(image, label):\n",
    "  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
    "  return image, label\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "\n",
    "validation_batches = validation_set.map(format_image).batch(BATCH_SIZE).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}